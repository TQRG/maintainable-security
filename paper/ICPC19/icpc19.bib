@article{Reis:2017:IJSSE,
 author = {Reis, Sofia and Abreu, Rui},
 title = {A Database of Existing Vulnerabilities to Enable Controlled Testing Studies},
 journal = {International Journal of Secure Software Engineering (IJSSE)},
 issue_date = {2017},
 volume = {8},
 number = {3},
 year = {2017},
 numpages = {1-23},
 url = {https://www.igi-global.com/article/a-database-of-existing-vulnerabilities-to-enable-controlled-testing-studies/201213},
 doi = {10.4018/IJSSE.2017070101},
 acmid = {1330021},
 publisher = {IGI Global}
 }

 @inproceedings{just2014mutants,
   title={Are mutants a valid substitute for real faults in software testing?},
   author={Just, Ren{\'e} and Jalali, Darioush and Inozemtseva, Laura and Ernst, Michael D and Holmes, Reid and Fraser, Gordon},
   booktitle={Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
   pages={654--665},
   year={2014},
   organization={ACM}
 }

 @INPROCEEDINGS{7816479,
 author={H. Borges and A. Hora and M. T. Valente},
 booktitle={2016 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
 title={Understanding the Factors That Impact the Popularity of GitHub Repositories},
 year={2016},
 volume={},
 number={},
 pages={334-344},
 keywords={public domain software;software reviews;source code (software);time series;GitHub Repositories;open source developers;software acceptance;software system popularity;open source software;stargazers button;GitHub projects;programming language;project popularity;time series;software market;Software;Libraries;Organizations;Documentation;HTML;Java;GitHub;Software Popularity;Open Source software;Social coding},
 doi={10.1109/ICSME.2016.31},
 ISSN={},
 month={Oct},}

 @INPROCEEDINGS{7476680,
 author={I. Kádár and P. Hegedus and R. Ferenc and T. Gyimóthy},
 booktitle={2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)},
 title={A Code Refactoring Dataset and Its Assessment Regarding Software Maintainability},
 year={2016},
 volume={1},
 number={},
 pages={599-603},
 keywords={public domain software;software maintenance;software metrics;software reliability;source code (software);code refactoring dataset processing;excessive open dataset;source code metrics;open-source systems;quality attributes;source code classes;clone metrics;software maintainability;Measurement;Cloning;Open source software;Correlation;Java;Complexity theory;code refactoring;software maintainability;empirical study},
 doi={10.1109/SANER.2016.42},
 ISSN={},
 month={March},}

 @article{HEGEDUS2018313,
 title = "Empirical evaluation of software maintainability based on a manually validated refactoring dataset",
 journal = "Information and Software Technology",
 volume = "95",
 pages = "313 - 327",
 year = "2018",
 issn = "0950-5849",
 doi = "https://doi.org/10.1016/j.infsof.2017.11.012",
 url = "http://www.sciencedirect.com/science/article/pii/S0950584916303561",
 author = "Péter Hegedűs and István Kádár and Rudolf Ferenc and Tibor Gyimóthy",
 keywords = "Code refactoring, Manually validated empirical dataset, Source code metrics, Software maintainability, Empirical study",
 abstract = "Context
 Refactoring is a technique for improving the internal structure of software systems. It has a solid theoretical background while being used in development practice also. However, we lack empirical research results on the real effect of code refactoring and its application.
 Objective
 This paper presents a manually validated subset of a previously published dataset containing the refactorings extracted by the RefFinder tool, code metrics, and maintainability of 7 open-source systems. We found that RefFinder had around 27% overall average precision on the subject systems, thus our manually validated subset has substantial added value. Using the dataset, we studied several aspects of the refactored and non-refactored source code elements (classes and methods), like the differences in their maintainability and source code metrics.
 Method
 We divided the source code elements into a group containing the refactored elements and a group with non-refactored elements. We analyzed the elements’ characteristics in these groups using correlation analysis, Mann–Whitney U test and effect size measures.
 Results
 Source code elements subjected to refactorings had significantly lower maintainability than elements not affected by refactorings. Moreover, refactored elements had significantly higher size related metrics, complexity, and coupling. Also these metrics changed more significantly in the refactored elements. The results are mostly in line with our previous findings on the not validated dataset, with the difference that clone metrics had no strong connection with refactoring.
 Conclusions
 Compared to the preliminary analysis using a not validated dataset, the manually validated dataset led to more significant results, which suggests that developers find targets for refactorings based on some internal quality properties of the source code, like their size, complexity or coupling, but not clone related metrics as reported in our previous studies. They do not just use these properties for identifying targets, but also control them with refactorings."
 }

 @ARTICLE{1702388,
 author={T. J. McCabe},
 journal={IEEE Transactions on Software Engineering},
 title={A Complexity Measure},
 year={1976},
 volume={SE-2},
 number={4},
 pages={308-320},
 keywords={Basis;complexity measure;control flow;decomposition;graph theory;independence;linear;modularization;programming;reduction;software;testing;Software testing;System testing;Graph theory;Fluid flow measurement;Software measurement;Linear programming;Software engineering;Software systems;Software maintenance;National security;Basis;complexity measure;control flow;decomposition;graph theory;independence;linear;modularization;programming;reduction;software;testing},
 doi={10.1109/TSE.1976.233837},
 ISSN={0098-5589},
 month={Dec}}

@book{iso:2011,
  title = {International Standard ISO/IEC 25010. Systems and Software Engineering - Systems and software Quality Requirements and Evaluation (SQuaRE) - System and Software Quality Models},
   year = {2011}
}

 @article{graw:1992,
   title={A common language effect size statistic. Psychological Bulletin},
   author={McGraw, Kenneth O. and Wong, S. P.},
   year={1992},
   doi={doi:10.1037/0033-2909.111.2.361}
 }

 @article{10.2307/2282543,
  ISSN = {01621459},
  URL = {http://www.jstor.org/stable/2282543},
  abstract = {A Wilcoxon one-sample signed rank test may be made when some of the observations are 0 by dropping the 0's before ranking. However, a sample can be not significantly positive while a more negative sample (obtained by decreasing each observation equally), is significantly positive by the ordinary Wilcoxon test. The reverse is also possible. Two-piece confidence regions result. A procedure for avoiding these difficulties is proposed, namely to rank the observations including the 0's, drop the ranks of the 0's, and reject the null hypothesis if the sum of the remaining negative (or positive) ranks falls in the tail of its null distribution (given the number of 0's). If observations are tied in absolute value, their ranks may be averaged before attaching signs. This changes the null distribution. A sample may be significantly positive which is not significant if the observations are increased (unequally), or if the ties are broken in any way.},
  author = {John W. Pratt},
  journal = {Journal of the American Statistical Association},
  number = {287},
  pages = {655--667},
  publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
  title = {Remarks on Zeros and Ties in the Wilcoxon Signed Rank Procedures},
  volume = {54},
  year = {1959}
 }




 @article{borges2015popularity,
   title={On the popularity of GitHub applications: A preliminary note},
   author={Borges, Hudson and Valente, Marco Tulio and Hora, Andre and Coelho, Jailton},
   journal={arXiv preprint arXiv:1507.00604},
   year={2015}
 }

 @article{10.2307/3001968,
  ISSN = {00994987},
  URL = {http://www.jstor.org/stable/3001968},
  author = {Frank Wilcoxon},
  journal = {Biometrics Bulletin},
  number = {6},
  pages = {80--83},
  publisher = {[International Biometric Society, Wiley]},
  title = {Individual Comparisons by Ranking Methods},
  volume = {1},
  year = {1945}
 }
 
 @Article{Baggen2012,
 author="Baggen, Robert
 and Correia, Jos{\'e} Pedro
 and Schill, Katrin
 and Visser, Joost",
 title="Standardized code quality benchmarking for improving software maintainability",
 journal="Software Quality Journal",
 year="2012",
 month="Jun",
 day="01",
 volume="20",
 number="2",
 pages="287--307",
 abstract="We provide an overview of the approach developed by the Software Improvement Group for code analysis and quality consulting focused on software maintainability. The approach uses a standardized measurement model based on the ISO/IEC 9126 definition of maintainability and source code metrics. Procedural standardization in evaluation projects further enhances the comparability of results. Individual assessments are stored in a repository that allows any system at hand to be compared to the industry-wide state of the art in code quality and maintainability. When a minimum level of software maintainability is reached, the certification body of T{\"U}V Informationstechnik GmbH issues a Trusted Product Maintainability certificate for the software product.",
 issn="1573-1367",
 doi="10.1007/s11219-011-9144-9",
 url="https://doi.org/10.1007/s11219-011-9144-9"
 }
 
 
 @MastersThesis{Olivari:2018,
     author     =     {Michael Olivari},
     title     =     {{Maintainable Production: A Model of Developer Productivity Based on
Source Code Contributions}},
     school     =     {University of Amsterdam},
     year     =     {2018},
     }

@article{baggen2012standardized,
  title={Standardized code quality benchmarking for improving software maintainability},
  author={Baggen, Robert and Correia, Jos{\'e} Pedro and Schill, Katrin and Visser, Joost},
  journal={Software Quality Journal},
  volume={20},
  number={2},
  pages={287--307},
  year={2012},
  publisher={Springer}
}

@article{da2017framework,
	Author = {da Costa, Daniel Alencar and McIntosh, Shane and Shang, Weiyi and Kulesza, Uir{\'a} and Coelho, Roberta and Hassan, Ahmed E},
	Journal = {IEEE Transactions on Software Engineering},
	Number = {7},
	Pages = {641--657},
	Publisher = {IEEE},
	Title = {A framework for evaluating the results of the szz approach for identifying bug-introducing changes},
	Volume = {43},
	Year = {2017}
}

@inproceedings{pascarella2018self,
	Author = {Pascarella, Luca and Geiger, Franz-Xaver and Palomba, Fabio and Di Nucci, Dario and Malavolta, Ivano and Bacchelli, Alberto},
	Booktitle = {5th IEEE/ACM International Conference on Mobile Software Engineering and Systems, New York, NY},
	Title = {Self-Reported Activities of Android Developers},
	Year = {2018}
}

@book{Visser:2016:OREILLY,
  author = {Joost Visser},
  title = {Building Maintainable Software, Java Edition: Ten Guidelines for Future-Proof Code},
  issue_date = {2016},
  publisher = {O'Reilly Media, Inc.}
  }


@techreport{oswap:2017,
	author ={The OWASP Foundation},
	title       = {OWASP Top 10 - 2017: The Ten Most Critical Web Application Security Risks},
	institution = {The OWASP Foundation},
	month       = {February},
	year        = {2017},
	note =  {Release Candidate}
}

@techreport{oswap:2013,
	author ={The OWASP Foundation},
	title       = {OWASP Top 10 - 2017: The Ten Most Critical Web Application Security Risks},
	institution = {The OWASP Foundation},
	month       = {February},
	year        = {2017},
	note =  {Release Candidate}
}
